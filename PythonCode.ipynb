{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('pima-indians-diabetes_test.data', header = None)\n",
    "train = pd.read_csv('pima-indians-diabetes_train.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['pregnant', 'glucose', 'bloodpressure', 'skin', 'ilsulin', 'bmi' ,'diabetes_faimily','age', 'class']\n",
    "test.columns = col\n",
    "train.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   pregnant          100 non-null    int64  \n",
      " 1   glucose           100 non-null    int64  \n",
      " 2   bloodpressure     100 non-null    int64  \n",
      " 3   skin              100 non-null    int64  \n",
      " 4   ilsulin           100 non-null    int64  \n",
      " 5   bmi               100 non-null    float64\n",
      " 6   diabetes_faimily  100 non-null    float64\n",
      " 7   age               100 non-null    int64  \n",
      " 8   class             100 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:8]\n",
    "y_train = train.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:8]\n",
    "y_test = test.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>ilsulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_faimily</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>9</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.637</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.245</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>132</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.217</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  bloodpressure  skin  ilsulin   bmi  diabetes_faimily  \\\n",
       "0           6      148             72    35        0  33.6             0.627   \n",
       "1           1       85             66    29        0  26.6             0.351   \n",
       "2           8      183             64     0        0  23.3             0.672   \n",
       "3           1       89             66    23       94  28.1             0.167   \n",
       "4           0      137             40    35      168  43.1             2.288   \n",
       "..        ...      ...            ...   ...      ...   ...               ...   \n",
       "663         9      145             80    46      130  37.9             0.637   \n",
       "664         6      115             60    39        0  33.7             0.245   \n",
       "665         1      112             80    45      132  34.8             0.217   \n",
       "666         4      145             82    18        0  32.5             0.235   \n",
       "667        10      111             70    27        0  27.5             0.141   \n",
       "\n",
       "     age  \n",
       "0     50  \n",
       "1     31  \n",
       "2     32  \n",
       "3     21  \n",
       "4     33  \n",
       "..   ...  \n",
       "663   40  \n",
       "664   40  \n",
       "665   24  \n",
       "666   70  \n",
       "667   40  \n",
       "\n",
       "[668 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers, num_nod, drop_rate, lr):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = 8))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for iterzz in range(0,num_layers):\n",
    "        model.add(keras.layers.Dense(num_nod, activation = 'selu', kernel_initializer = 'lecun_normal'))\n",
    "        model.add(keras.layers.AlphaDropout(rate = drop_rate))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer = 'lecun_normal'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X, y, num_layers, num_nod, drop_rate, lr, k):\n",
    "    folds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 201600177)\n",
    "    acc = []\n",
    "    for train_idx, val_idx in folds.split(X,y):\n",
    "        X_cv_train = X.iloc[train_idx,]\n",
    "        y_cv_train = y[train_idx]\n",
    "        X_cv_valid = X.iloc[val_idx,]\n",
    "        y_cv_valid = y[val_idx]\n",
    "        model = None\n",
    "        model = build_model(num_layers, num_nod, drop_rate, lr)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "        model.fit(X_cv_train, y_cv_train, epochs = 10000, callbacks = callback, batch_size = 128, verbose = 0)\n",
    "        acc.append(model.evaluate(X_cv_valid, y_cv_valid, verbose = 0)[1])\n",
    "    return(sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exapnd_grid(num_layers, num_nods, drop_rate, lr):\n",
    "    return(np.array([(aa, ab, round(ac,5), round(ad,5)) for aa in num_layers for ab in num_nods for ac in drop_rate for ad in lr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = exapnd_grid(np.arange(1,4), np.arange(20,210,30), np.arange(0.05,0.2,0.05), [0.0001, 0.001, 0.01, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, gr, k):\n",
    "    accl = []\n",
    "    start = time.time()\n",
    "    for i,g in enumerate(gr):\n",
    "        accl.append(k_fold(X, y, int(g[0]), int(g[1]), g[2], g[3], k))\n",
    "        print(f'{i}/{len(gr)-1}')\n",
    "    return([gr[accl.index(max(accl))], max(accl), time.time() - start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/335\n",
      "1/335\n",
      "2/335\n",
      "3/335\n",
      "4/335\n",
      "5/335\n",
      "6/335\n",
      "7/335\n",
      "8/335\n",
      "9/335\n",
      "10/335\n",
      "11/335\n",
      "12/335\n",
      "13/335\n",
      "14/335\n",
      "15/335\n",
      "16/335\n",
      "17/335\n",
      "18/335\n",
      "19/335\n",
      "20/335\n",
      "21/335\n",
      "22/335\n",
      "23/335\n",
      "24/335\n",
      "25/335\n",
      "26/335\n",
      "27/335\n",
      "28/335\n",
      "29/335\n",
      "30/335\n",
      "31/335\n",
      "32/335\n",
      "33/335\n",
      "34/335\n",
      "35/335\n",
      "36/335\n",
      "37/335\n",
      "38/335\n",
      "39/335\n",
      "40/335\n",
      "41/335\n",
      "42/335\n",
      "43/335\n",
      "44/335\n",
      "45/335\n",
      "46/335\n",
      "47/335\n",
      "48/335\n",
      "49/335\n",
      "50/335\n",
      "51/335\n",
      "52/335\n",
      "53/335\n",
      "54/335\n",
      "55/335\n",
      "56/335\n",
      "57/335\n",
      "58/335\n",
      "59/335\n",
      "60/335\n",
      "61/335\n",
      "62/335\n",
      "63/335\n",
      "64/335\n",
      "65/335\n",
      "66/335\n",
      "67/335\n",
      "68/335\n",
      "69/335\n",
      "70/335\n",
      "71/335\n",
      "72/335\n",
      "73/335\n",
      "74/335\n",
      "75/335\n",
      "76/335\n",
      "77/335\n",
      "78/335\n",
      "79/335\n",
      "80/335\n",
      "81/335\n",
      "82/335\n",
      "83/335\n",
      "84/335\n",
      "85/335\n",
      "86/335\n",
      "87/335\n",
      "88/335\n",
      "89/335\n",
      "90/335\n",
      "91/335\n",
      "92/335\n",
      "93/335\n",
      "94/335\n",
      "95/335\n",
      "96/335\n",
      "97/335\n",
      "98/335\n",
      "99/335\n",
      "100/335\n",
      "101/335\n",
      "102/335\n",
      "103/335\n",
      "104/335\n",
      "105/335\n",
      "106/335\n",
      "107/335\n",
      "108/335\n",
      "109/335\n",
      "110/335\n",
      "111/335\n",
      "112/335\n",
      "113/335\n",
      "114/335\n",
      "115/335\n",
      "116/335\n",
      "117/335\n",
      "118/335\n",
      "119/335\n",
      "120/335\n",
      "121/335\n",
      "122/335\n",
      "123/335\n",
      "124/335\n",
      "125/335\n",
      "126/335\n",
      "127/335\n",
      "128/335\n",
      "129/335\n",
      "130/335\n",
      "131/335\n",
      "132/335\n",
      "133/335\n",
      "134/335\n",
      "135/335\n",
      "136/335\n",
      "137/335\n",
      "138/335\n",
      "139/335\n",
      "140/335\n",
      "141/335\n",
      "142/335\n",
      "143/335\n",
      "144/335\n",
      "145/335\n",
      "146/335\n",
      "147/335\n",
      "148/335\n",
      "149/335\n",
      "150/335\n",
      "151/335\n",
      "152/335\n",
      "153/335\n",
      "154/335\n",
      "155/335\n",
      "156/335\n",
      "157/335\n",
      "158/335\n",
      "159/335\n",
      "160/335\n",
      "161/335\n",
      "162/335\n",
      "163/335\n",
      "164/335\n",
      "165/335\n",
      "166/335\n",
      "167/335\n",
      "168/335\n",
      "169/335\n",
      "170/335\n",
      "171/335\n",
      "172/335\n",
      "173/335\n",
      "174/335\n",
      "175/335\n",
      "176/335\n",
      "177/335\n",
      "178/335\n",
      "179/335\n",
      "180/335\n",
      "181/335\n",
      "182/335\n",
      "183/335\n",
      "184/335\n",
      "185/335\n",
      "186/335\n",
      "187/335\n",
      "188/335\n",
      "189/335\n",
      "190/335\n",
      "191/335\n",
      "192/335\n",
      "193/335\n",
      "194/335\n",
      "195/335\n",
      "196/335\n",
      "197/335\n",
      "198/335\n",
      "199/335\n",
      "200/335\n",
      "201/335\n",
      "202/335\n",
      "203/335\n",
      "204/335\n",
      "205/335\n",
      "206/335\n",
      "207/335\n",
      "208/335\n",
      "209/335\n",
      "210/335\n",
      "211/335\n",
      "212/335\n",
      "213/335\n",
      "214/335\n",
      "215/335\n",
      "216/335\n",
      "217/335\n",
      "218/335\n",
      "219/335\n",
      "220/335\n",
      "221/335\n",
      "222/335\n",
      "223/335\n",
      "224/335\n",
      "225/335\n",
      "226/335\n",
      "227/335\n",
      "228/335\n",
      "229/335\n",
      "230/335\n",
      "231/335\n",
      "232/335\n",
      "233/335\n",
      "234/335\n",
      "235/335\n",
      "236/335\n",
      "237/335\n",
      "238/335\n",
      "239/335\n",
      "240/335\n",
      "241/335\n",
      "242/335\n",
      "243/335\n",
      "244/335\n",
      "245/335\n",
      "246/335\n",
      "247/335\n",
      "248/335\n",
      "249/335\n",
      "250/335\n",
      "251/335\n",
      "252/335\n",
      "253/335\n",
      "254/335\n",
      "255/335\n",
      "256/335\n",
      "257/335\n",
      "258/335\n",
      "259/335\n",
      "260/335\n",
      "261/335\n",
      "262/335\n",
      "263/335\n",
      "264/335\n",
      "265/335\n",
      "266/335\n",
      "267/335\n",
      "268/335\n",
      "269/335\n",
      "270/335\n",
      "271/335\n",
      "272/335\n",
      "273/335\n",
      "274/335\n",
      "275/335\n",
      "276/335\n",
      "277/335\n",
      "278/335\n",
      "279/335\n",
      "280/335\n",
      "281/335\n",
      "282/335\n",
      "283/335\n",
      "284/335\n",
      "285/335\n",
      "286/335\n",
      "287/335\n",
      "288/335\n",
      "289/335\n",
      "290/335\n",
      "291/335\n",
      "292/335\n",
      "293/335\n",
      "294/335\n",
      "295/335\n",
      "296/335\n",
      "297/335\n",
      "298/335\n",
      "299/335\n",
      "300/335\n",
      "301/335\n",
      "302/335\n",
      "303/335\n",
      "304/335\n",
      "305/335\n",
      "306/335\n",
      "307/335\n",
      "308/335\n",
      "309/335\n",
      "310/335\n",
      "311/335\n",
      "312/335\n",
      "313/335\n",
      "314/335\n",
      "315/335\n",
      "316/335\n",
      "317/335\n",
      "318/335\n",
      "319/335\n",
      "320/335\n",
      "321/335\n",
      "322/335\n",
      "323/335\n",
      "324/335\n",
      "325/335\n",
      "326/335\n",
      "327/335\n",
      "328/335\n",
      "329/335\n",
      "330/335\n",
      "331/335\n",
      "332/335\n",
      "333/335\n",
      "334/335\n",
      "335/335\n"
     ]
    }
   ],
   "source": [
    "result = grid_search(X_train, y_train, grid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "[array([2.e+00, 2.e+01, 1.e-01, 1.e-04]), 0.7799638211727142, 13005.478254318237]\n"
     ]
    }
   ],
   "source": [
    "print(len(grid))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - 1s 6ms/step - loss: 0.9046 - accuracy: 0.4506\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8829 - accuracy: 0.4536\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8259 - accuracy: 0.4865\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8100 - accuracy: 0.5195\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.8121 - accuracy: 0.5045\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7499 - accuracy: 0.5284\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7386 - accuracy: 0.5674\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.7202 - accuracy: 0.5793\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.6048\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.6093\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6883 - accuracy: 0.6183\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6392\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6572\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6289 - accuracy: 0.6647\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.6707\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6205 - accuracy: 0.6452\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.6751\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.6692\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.6437\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.6722\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5929 - accuracy: 0.7006\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.6871\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.6961\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5726 - accuracy: 0.6976\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.6901\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.7111\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.6677\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7126\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.6976\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7036\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7021\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7171\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7260\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5683 - accuracy: 0.6856\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.7365\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7246\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7156\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7260\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7156\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7201\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7290\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7126\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.7440\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7156\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7216\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7111\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7260\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7350\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7365\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7365\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7126\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7560\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7455\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7290\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7290\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5503 - accuracy: 0.7246\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7485\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7560\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7470\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7455\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7141\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7305\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7171\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7470\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5369 - accuracy: 0.7410\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5268 - accuracy: 0.7410\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.7545\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7365\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7156\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5020 - accuracy: 0.7575\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7545\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7305\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.7320\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7425\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7440\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7410\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5197 - accuracy: 0.7440\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7350\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7365\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.7605\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7365\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7365\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7395\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7545\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7545\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7425\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7246\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7335\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5039 - accuracy: 0.7605\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7141\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7530\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7455\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.7545\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7440\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7515\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7365\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5059 - accuracy: 0.7575\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.7455\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7740\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cfbacdfe50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = build_model(int(result[0][0]), int(result[0][1]), result[0][2], result[0][3])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "tuned_model.fit(X_train, y_train, epochs = 10000, callbacks = callback, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49931854009628296, 0.7799999713897705]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11634299366819952112,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 7020688179\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 13694658950082813815\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:26:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
