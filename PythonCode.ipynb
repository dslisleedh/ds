{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('pima-indians-diabetes_test.data', header = None)\n",
    "train = pd.read_csv('pima-indians-diabetes_train.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['pregnant', 'glucose', 'bloodpressure', 'skin', 'ilsulin', 'bmi' ,'diabetes_faimily','age', 'class']\n",
    "test.columns = col\n",
    "train.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   pregnant          100 non-null    int64  \n",
      " 1   glucose           100 non-null    int64  \n",
      " 2   bloodpressure     100 non-null    int64  \n",
      " 3   skin              100 non-null    int64  \n",
      " 4   ilsulin           100 non-null    int64  \n",
      " 5   bmi               100 non-null    float64\n",
      " 6   diabetes_faimily  100 non-null    float64\n",
      " 7   age               100 non-null    int64  \n",
      " 8   class             100 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:8]\n",
    "y_train = train.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:8]\n",
    "y_test = test.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>ilsulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_faimily</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>9</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.637</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.245</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>132</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.217</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  bloodpressure  skin  ilsulin   bmi  diabetes_faimily  \\\n",
       "0           6      148             72    35        0  33.6             0.627   \n",
       "1           1       85             66    29        0  26.6             0.351   \n",
       "2           8      183             64     0        0  23.3             0.672   \n",
       "3           1       89             66    23       94  28.1             0.167   \n",
       "4           0      137             40    35      168  43.1             2.288   \n",
       "..        ...      ...            ...   ...      ...   ...               ...   \n",
       "663         9      145             80    46      130  37.9             0.637   \n",
       "664         6      115             60    39        0  33.7             0.245   \n",
       "665         1      112             80    45      132  34.8             0.217   \n",
       "666         4      145             82    18        0  32.5             0.235   \n",
       "667        10      111             70    27        0  27.5             0.141   \n",
       "\n",
       "     age  \n",
       "0     50  \n",
       "1     31  \n",
       "2     32  \n",
       "3     21  \n",
       "4     33  \n",
       "..   ...  \n",
       "663   40  \n",
       "664   40  \n",
       "665   24  \n",
       "666   70  \n",
       "667   40  \n",
       "\n",
       "[668 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers, num_nod, drop_rate, lr):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = 8))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for iterzz in range(0,num_layers):\n",
    "        model.add(keras.layers.Dense(num_nod, activation = 'selu', kernel_initializer = 'lecun_normal'))\n",
    "        model.add(keras.layers.AlphaDropout(rate = drop_rate))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer = 'lecun_normal'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X, y, num_layers, num_nod, drop_rate, lr, k):\n",
    "    folds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 201600177)\n",
    "    acc = []\n",
    "    for train_idx, val_idx in folds.split(X,y):\n",
    "        X_cv_train = X.iloc[train_idx,]\n",
    "        y_cv_train = y[train_idx]\n",
    "        X_cv_valid = X.iloc[val_idx,]\n",
    "        y_cv_valid = y[val_idx]\n",
    "        model = None\n",
    "        model = build_model(num_layers, num_nod, drop_rate, lr)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "        model.fit(X_cv_train, y_cv_train, epochs = 10000, callbacks = callback, batch_size = 128, verbose = 0)\n",
    "        acc.append(model.evaluate(X_cv_valid, y_cv_valid, verbose = 0)[1])\n",
    "    return(sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exapnd_grid(num_layers, num_nods, drop_rate, lr):\n",
    "    return(np.array([(aa, ab, round(ac,5), round(ad,5)) for aa in num_layers for ab in num_nods for ac in drop_rate for ad in lr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = exapnd_grid(np.arange(1,4), np.arange(20,210,30), np.arange(0.05,0.2,0.05), [0.0001, 0.001, 0.01, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, gr, k):\n",
    "    accl = []\n",
    "    start = time.time()\n",
    "    for i,g in enumerate(gr):\n",
    "        accl.append(k_fold(X, y, int(g[0]), int(g[1]), g[2], g[3], 5))\n",
    "        print(f'{i}/{len(gr)}')\n",
    "    return([gr[accl.index(max(accl))], max(accl), time.time() - start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/336\n",
      "1/336\n",
      "2/336\n",
      "3/336\n",
      "4/336\n",
      "5/336\n",
      "6/336\n",
      "7/336\n",
      "8/336\n",
      "9/336\n",
      "10/336\n",
      "11/336\n",
      "12/336\n",
      "13/336\n",
      "14/336\n",
      "15/336\n",
      "16/336\n",
      "17/336\n",
      "18/336\n",
      "19/336\n",
      "20/336\n",
      "21/336\n",
      "22/336\n",
      "23/336\n",
      "24/336\n",
      "25/336\n",
      "26/336\n",
      "27/336\n",
      "28/336\n",
      "29/336\n",
      "30/336\n",
      "31/336\n",
      "32/336\n",
      "33/336\n",
      "34/336\n",
      "35/336\n",
      "36/336\n",
      "37/336\n",
      "38/336\n",
      "39/336\n",
      "40/336\n",
      "41/336\n",
      "42/336\n",
      "43/336\n",
      "44/336\n",
      "45/336\n",
      "46/336\n",
      "47/336\n",
      "48/336\n",
      "49/336\n",
      "50/336\n",
      "51/336\n",
      "52/336\n",
      "53/336\n",
      "54/336\n",
      "55/336\n",
      "56/336\n",
      "57/336\n",
      "58/336\n",
      "59/336\n",
      "60/336\n",
      "61/336\n",
      "62/336\n",
      "63/336\n",
      "64/336\n",
      "65/336\n",
      "66/336\n",
      "67/336\n",
      "68/336\n",
      "69/336\n",
      "70/336\n",
      "71/336\n",
      "72/336\n",
      "73/336\n",
      "74/336\n",
      "75/336\n",
      "76/336\n",
      "77/336\n",
      "78/336\n",
      "79/336\n",
      "80/336\n",
      "81/336\n",
      "82/336\n",
      "83/336\n",
      "84/336\n",
      "85/336\n",
      "86/336\n",
      "87/336\n",
      "88/336\n",
      "89/336\n",
      "90/336\n",
      "91/336\n",
      "92/336\n",
      "93/336\n",
      "94/336\n",
      "95/336\n",
      "96/336\n",
      "97/336\n",
      "98/336\n",
      "99/336\n",
      "100/336\n",
      "101/336\n",
      "102/336\n",
      "103/336\n",
      "104/336\n",
      "105/336\n",
      "106/336\n",
      "107/336\n",
      "108/336\n",
      "109/336\n",
      "110/336\n",
      "111/336\n",
      "112/336\n",
      "113/336\n",
      "114/336\n",
      "115/336\n",
      "116/336\n",
      "117/336\n",
      "118/336\n",
      "119/336\n",
      "120/336\n",
      "121/336\n",
      "122/336\n",
      "123/336\n",
      "124/336\n",
      "125/336\n",
      "126/336\n",
      "127/336\n",
      "128/336\n",
      "129/336\n",
      "130/336\n",
      "131/336\n",
      "132/336\n",
      "133/336\n",
      "134/336\n",
      "135/336\n",
      "136/336\n",
      "137/336\n",
      "138/336\n",
      "139/336\n",
      "140/336\n",
      "141/336\n",
      "142/336\n",
      "143/336\n",
      "144/336\n",
      "145/336\n",
      "146/336\n",
      "147/336\n",
      "148/336\n",
      "149/336\n",
      "150/336\n",
      "151/336\n",
      "152/336\n",
      "153/336\n",
      "154/336\n",
      "155/336\n",
      "156/336\n",
      "157/336\n",
      "158/336\n",
      "159/336\n",
      "160/336\n",
      "161/336\n",
      "162/336\n",
      "163/336\n",
      "164/336\n",
      "165/336\n",
      "166/336\n",
      "167/336\n",
      "168/336\n",
      "169/336\n",
      "170/336\n",
      "171/336\n",
      "172/336\n",
      "173/336\n",
      "174/336\n",
      "175/336\n",
      "176/336\n",
      "177/336\n",
      "178/336\n",
      "179/336\n",
      "180/336\n",
      "181/336\n",
      "182/336\n",
      "183/336\n",
      "184/336\n",
      "185/336\n",
      "186/336\n",
      "187/336\n",
      "188/336\n",
      "189/336\n",
      "190/336\n",
      "191/336\n",
      "192/336\n",
      "193/336\n",
      "194/336\n",
      "195/336\n",
      "196/336\n",
      "197/336\n",
      "198/336\n",
      "199/336\n",
      "200/336\n",
      "201/336\n",
      "202/336\n",
      "203/336\n",
      "204/336\n",
      "205/336\n",
      "206/336\n",
      "207/336\n",
      "208/336\n",
      "209/336\n",
      "210/336\n",
      "211/336\n",
      "212/336\n",
      "213/336\n",
      "214/336\n",
      "215/336\n",
      "216/336\n",
      "217/336\n",
      "218/336\n",
      "219/336\n",
      "220/336\n",
      "221/336\n",
      "222/336\n",
      "223/336\n",
      "224/336\n",
      "225/336\n",
      "226/336\n",
      "227/336\n",
      "228/336\n",
      "229/336\n",
      "230/336\n",
      "231/336\n",
      "232/336\n",
      "233/336\n",
      "234/336\n",
      "235/336\n",
      "236/336\n",
      "237/336\n",
      "238/336\n",
      "239/336\n",
      "240/336\n",
      "241/336\n",
      "242/336\n",
      "243/336\n",
      "244/336\n",
      "245/336\n",
      "246/336\n",
      "247/336\n",
      "248/336\n",
      "249/336\n",
      "250/336\n",
      "251/336\n",
      "252/336\n",
      "253/336\n",
      "254/336\n",
      "255/336\n",
      "256/336\n",
      "257/336\n",
      "258/336\n",
      "259/336\n",
      "260/336\n",
      "261/336\n",
      "262/336\n",
      "263/336\n",
      "264/336\n",
      "265/336\n",
      "266/336\n",
      "267/336\n",
      "268/336\n",
      "269/336\n",
      "270/336\n",
      "271/336\n",
      "272/336\n",
      "273/336\n",
      "274/336\n",
      "275/336\n",
      "276/336\n",
      "277/336\n",
      "278/336\n",
      "279/336\n",
      "280/336\n",
      "281/336\n",
      "282/336\n",
      "283/336\n",
      "284/336\n",
      "285/336\n",
      "286/336\n",
      "287/336\n",
      "288/336\n",
      "289/336\n",
      "290/336\n",
      "291/336\n",
      "292/336\n",
      "293/336\n",
      "294/336\n",
      "295/336\n",
      "296/336\n",
      "297/336\n",
      "298/336\n",
      "299/336\n",
      "300/336\n",
      "301/336\n",
      "302/336\n",
      "303/336\n",
      "304/336\n",
      "305/336\n",
      "306/336\n",
      "307/336\n",
      "308/336\n",
      "309/336\n",
      "310/336\n",
      "311/336\n",
      "312/336\n",
      "313/336\n",
      "314/336\n",
      "315/336\n",
      "316/336\n",
      "317/336\n",
      "318/336\n",
      "319/336\n",
      "320/336\n",
      "321/336\n",
      "322/336\n",
      "323/336\n",
      "324/336\n",
      "325/336\n",
      "326/336\n",
      "327/336\n",
      "328/336\n",
      "329/336\n",
      "330/336\n",
      "331/336\n",
      "332/336\n",
      "333/336\n",
      "334/336\n",
      "335/336\n"
     ]
    }
   ],
   "source": [
    "result = grid_search(X_train, y_train, grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "[array([1.e+00, 5.e+01, 5.e-02, 1.e-02]), 0.774009644985199, 6007.923990726471]\n"
     ]
    }
   ],
   "source": [
    "print(len(grid))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8213 - accuracy: 0.4117\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7901 - accuracy: 0.4326\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7464 - accuracy: 0.4820\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7291 - accuracy: 0.5015\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5584\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.5569\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.6123\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6247 - accuracy: 0.6677\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6497\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.6871\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.6722\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.6737\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.6811\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7021\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5632 - accuracy: 0.7051\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7066\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7006\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5561 - accuracy: 0.7156\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7066\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7036\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7320\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7275\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7305\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7305\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7365\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7380\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7575\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7275\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7485\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7395\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7440\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7410\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7350\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7455\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7320\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7440\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7395\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7590\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7410\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7305\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.7530\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7440\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7680\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7530\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7425\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7530\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7335\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7545\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7545\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7380\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7335\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7590\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7455\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7725\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7740\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7545\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7665\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7515\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4801 - accuracy: 0.7769\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4906 - accuracy: 0.7590\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.7680\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7560\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7485\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7440\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7590\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7635\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7560\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7680\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7725\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.7710\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.7515\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7680\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4836 - accuracy: 0.7725\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7620\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4930 - accuracy: 0.7620\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7754\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7680\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7590\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7665\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7605\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7680\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7620\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7635\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7530\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.7515\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bf034d6670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = build_model(int(result[0][0]), int(result[0][1]), result[0][2], result[0][3])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "tuned_model.fit(X_train, y_train, epochs = 10000, callbacks = callback, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49892035126686096, 0.7799999713897705]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
