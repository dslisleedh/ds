{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "커널초기화 : 르쿤초기화 Dense(kernel_initializer = 'lecun_normal')  \n",
    "활성화함수 : selu Dense( activation = 'selu')  \n",
    "정규화 : 배치정규화  \n",
    "규제 : 알파 드롭아웃(drop_rate=최적화)  \n",
    "옵티마이저 : 모멘텀 최적화 optimizer = keras.optimizers.SGD(lr = 최적화, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('pima-indians-diabetes_test.data', header = None)\n",
    "train = pd.read_csv('pima-indians-diabetes_train.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['pregnant', 'glucose', 'bloodpressure', 'skin', 'ilsulin', 'bmi' ,'diabetes_faimily','age', 'class']\n",
    "test.columns = col\n",
    "train.columns = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   pregnant          100 non-null    int64  \n",
      " 1   glucose           100 non-null    int64  \n",
      " 2   bloodpressure     100 non-null    int64  \n",
      " 3   skin              100 non-null    int64  \n",
      " 4   ilsulin           100 non-null    int64  \n",
      " 5   bmi               100 non-null    float64\n",
      " 6   diabetes_faimily  100 non-null    float64\n",
      " 7   age               100 non-null    int64  \n",
      " 8   class             100 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 7.2 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,:8]\n",
    "y_train = train.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:,:8]\n",
    "y_test = test.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bloodpressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>ilsulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>diabetes_faimily</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>9</td>\n",
       "      <td>145</td>\n",
       "      <td>80</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.637</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>6</td>\n",
       "      <td>115</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.245</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>132</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.217</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose  bloodpressure  skin  ilsulin   bmi  diabetes_faimily  \\\n",
       "0           6      148             72    35        0  33.6             0.627   \n",
       "1           1       85             66    29        0  26.6             0.351   \n",
       "2           8      183             64     0        0  23.3             0.672   \n",
       "3           1       89             66    23       94  28.1             0.167   \n",
       "4           0      137             40    35      168  43.1             2.288   \n",
       "..        ...      ...            ...   ...      ...   ...               ...   \n",
       "663         9      145             80    46      130  37.9             0.637   \n",
       "664         6      115             60    39        0  33.7             0.245   \n",
       "665         1      112             80    45      132  34.8             0.217   \n",
       "666         4      145             82    18        0  32.5             0.235   \n",
       "667        10      111             70    27        0  27.5             0.141   \n",
       "\n",
       "     age  \n",
       "0     50  \n",
       "1     31  \n",
       "2     32  \n",
       "3     21  \n",
       "4     33  \n",
       "..   ...  \n",
       "663   40  \n",
       "664   40  \n",
       "665   24  \n",
       "666   70  \n",
       "667   40  \n",
       "\n",
       "[668 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_layers, num_nod, drop_rate, lr):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape = 8))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for iterzz in range(0,num_layers):\n",
    "        model.add(keras.layers.Dense(num_nod, activation = 'selu', kernel_initializer = 'lecun_normal'))\n",
    "        model.add(keras.layers.AlphaDropout(rate = drop_rate))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer = 'lecun_normal'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(X, y, num_layers, num_nod, drop_rate, lr, k):\n",
    "    folds = StratifiedKFold(n_splits = k, shuffle = True, random_state = 201600177)\n",
    "    acc = []\n",
    "    for train_idx, val_idx in folds.split(X,y):\n",
    "        X_cv_train = X.iloc[train_idx,]\n",
    "        y_cv_train = y[train_idx]\n",
    "        X_cv_valid = X.iloc[val_idx,]\n",
    "        y_cv_valid = y[val_idx]\n",
    "        model = None\n",
    "        model = build_model(num_layers, num_nod, drop_rate, lr)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "        model.fit(X_cv_train, y_cv_train, epochs = 100, callbacks = callback, batch_size = 128, verbose = 0)\n",
    "        acc.append(model.evaluate(X_cv_valid, y_cv_valid, verbose = 0)[1])\n",
    "    return(sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exapnd_grid(num_layers, num_nods, drop_rate, lr):\n",
    "    return(np.array([(aa, ab, round(ac,5), round(ad,5)) for aa in num_layers for ab in num_nods for ac in drop_rate for ad in lr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = exapnd_grid(np.arange(1,4), np.arange(20,210,30), np.arange(0.05,0.2,0.05), [0.0001, 0.001, 0.01, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, gr, k):\n",
    "    accl = []\n",
    "    start = time.time()\n",
    "    for i,g in enumerate(gr):\n",
    "        accl.append(k_fold(X, y, int(g[0]), int(g[1]), g[2], g[3], 5))\n",
    "        print(f'{i}/{len(gr)}')\n",
    "    return([gr[accl.index(max(accl))], max(accl), time.time() - start])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/336\n",
      "1/336\n",
      "2/336\n",
      "3/336\n",
      "4/336\n",
      "5/336\n",
      "6/336\n",
      "7/336\n",
      "8/336\n",
      "9/336\n",
      "10/336\n",
      "11/336\n",
      "12/336\n",
      "13/336\n",
      "14/336\n",
      "15/336\n",
      "16/336\n",
      "17/336\n",
      "18/336\n",
      "19/336\n",
      "20/336\n",
      "21/336\n",
      "22/336\n",
      "23/336\n",
      "24/336\n",
      "25/336\n",
      "26/336\n",
      "27/336\n",
      "28/336\n",
      "29/336\n",
      "30/336\n",
      "31/336\n",
      "32/336\n",
      "33/336\n",
      "34/336\n",
      "35/336\n",
      "36/336\n",
      "37/336\n",
      "38/336\n",
      "39/336\n",
      "40/336\n",
      "41/336\n",
      "42/336\n",
      "43/336\n",
      "44/336\n",
      "45/336\n",
      "46/336\n",
      "47/336\n",
      "48/336\n",
      "49/336\n",
      "50/336\n",
      "51/336\n",
      "52/336\n",
      "53/336\n",
      "54/336\n",
      "55/336\n",
      "56/336\n",
      "57/336\n",
      "58/336\n",
      "59/336\n",
      "60/336\n",
      "61/336\n",
      "62/336\n",
      "63/336\n",
      "64/336\n",
      "65/336\n",
      "66/336\n",
      "67/336\n",
      "68/336\n",
      "69/336\n",
      "70/336\n",
      "71/336\n",
      "72/336\n",
      "73/336\n",
      "74/336\n",
      "75/336\n",
      "76/336\n",
      "77/336\n",
      "78/336\n",
      "79/336\n",
      "80/336\n",
      "81/336\n",
      "82/336\n",
      "83/336\n",
      "84/336\n",
      "85/336\n",
      "86/336\n",
      "87/336\n",
      "88/336\n",
      "89/336\n",
      "90/336\n",
      "91/336\n",
      "92/336\n",
      "93/336\n",
      "94/336\n",
      "95/336\n",
      "96/336\n",
      "97/336\n",
      "98/336\n",
      "99/336\n",
      "100/336\n",
      "101/336\n",
      "102/336\n",
      "103/336\n",
      "104/336\n",
      "105/336\n",
      "106/336\n",
      "107/336\n",
      "108/336\n",
      "109/336\n",
      "110/336\n",
      "111/336\n",
      "112/336\n",
      "113/336\n",
      "114/336\n",
      "115/336\n",
      "116/336\n",
      "117/336\n",
      "118/336\n",
      "119/336\n",
      "120/336\n",
      "121/336\n",
      "122/336\n",
      "123/336\n",
      "124/336\n",
      "125/336\n",
      "126/336\n",
      "127/336\n",
      "128/336\n",
      "129/336\n",
      "130/336\n",
      "131/336\n",
      "132/336\n",
      "133/336\n",
      "134/336\n",
      "135/336\n",
      "136/336\n",
      "137/336\n",
      "138/336\n",
      "139/336\n",
      "140/336\n",
      "141/336\n",
      "142/336\n",
      "143/336\n",
      "144/336\n",
      "145/336\n",
      "146/336\n",
      "147/336\n",
      "148/336\n",
      "149/336\n",
      "150/336\n",
      "151/336\n",
      "152/336\n",
      "153/336\n",
      "154/336\n",
      "155/336\n",
      "156/336\n",
      "157/336\n",
      "158/336\n",
      "159/336\n",
      "160/336\n",
      "161/336\n",
      "162/336\n",
      "163/336\n",
      "164/336\n",
      "165/336\n",
      "166/336\n",
      "167/336\n",
      "168/336\n",
      "169/336\n",
      "170/336\n",
      "171/336\n",
      "172/336\n",
      "173/336\n",
      "174/336\n",
      "175/336\n",
      "176/336\n",
      "177/336\n",
      "178/336\n",
      "179/336\n",
      "180/336\n",
      "181/336\n",
      "182/336\n",
      "183/336\n",
      "184/336\n",
      "185/336\n",
      "186/336\n",
      "187/336\n",
      "188/336\n",
      "189/336\n",
      "190/336\n",
      "191/336\n",
      "192/336\n",
      "193/336\n",
      "194/336\n",
      "195/336\n",
      "196/336\n",
      "197/336\n",
      "198/336\n",
      "199/336\n",
      "200/336\n",
      "201/336\n",
      "202/336\n",
      "203/336\n",
      "204/336\n",
      "205/336\n",
      "206/336\n",
      "207/336\n",
      "208/336\n",
      "209/336\n",
      "210/336\n",
      "211/336\n",
      "212/336\n",
      "213/336\n",
      "214/336\n",
      "215/336\n",
      "216/336\n",
      "217/336\n",
      "218/336\n",
      "219/336\n",
      "220/336\n",
      "221/336\n",
      "222/336\n",
      "223/336\n",
      "224/336\n",
      "225/336\n",
      "226/336\n",
      "227/336\n",
      "228/336\n",
      "229/336\n",
      "230/336\n",
      "231/336\n",
      "232/336\n",
      "233/336\n",
      "234/336\n",
      "235/336\n",
      "236/336\n",
      "237/336\n",
      "238/336\n",
      "239/336\n",
      "240/336\n",
      "241/336\n",
      "242/336\n",
      "243/336\n",
      "244/336\n",
      "245/336\n",
      "246/336\n",
      "247/336\n",
      "248/336\n",
      "249/336\n",
      "250/336\n",
      "251/336\n",
      "252/336\n",
      "253/336\n",
      "254/336\n",
      "255/336\n",
      "256/336\n",
      "257/336\n",
      "258/336\n",
      "259/336\n",
      "260/336\n",
      "261/336\n",
      "262/336\n",
      "263/336\n",
      "264/336\n",
      "265/336\n",
      "266/336\n",
      "267/336\n",
      "268/336\n",
      "269/336\n",
      "270/336\n",
      "271/336\n",
      "272/336\n",
      "273/336\n",
      "274/336\n",
      "275/336\n",
      "276/336\n",
      "277/336\n",
      "278/336\n",
      "279/336\n",
      "280/336\n",
      "281/336\n",
      "282/336\n",
      "283/336\n",
      "284/336\n",
      "285/336\n",
      "286/336\n",
      "287/336\n",
      "288/336\n",
      "289/336\n",
      "290/336\n",
      "291/336\n",
      "292/336\n",
      "293/336\n",
      "294/336\n",
      "295/336\n",
      "296/336\n",
      "297/336\n",
      "298/336\n",
      "299/336\n",
      "300/336\n",
      "301/336\n",
      "302/336\n",
      "303/336\n",
      "304/336\n",
      "305/336\n",
      "306/336\n",
      "307/336\n",
      "308/336\n",
      "309/336\n",
      "310/336\n",
      "311/336\n",
      "312/336\n",
      "313/336\n",
      "314/336\n",
      "315/336\n",
      "316/336\n",
      "317/336\n",
      "318/336\n",
      "319/336\n",
      "320/336\n",
      "321/336\n",
      "322/336\n",
      "323/336\n",
      "324/336\n",
      "325/336\n",
      "326/336\n",
      "327/336\n",
      "328/336\n",
      "329/336\n",
      "330/336\n",
      "331/336\n",
      "332/336\n",
      "333/336\n",
      "334/336\n",
      "335/336\n"
     ]
    }
   ],
   "source": [
    "result = grid_search(X_train, y_train, grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "[array([1.0e+00, 1.1e+02, 2.0e-01, 1.0e-01]), 0.7754685282707214, 5332.0907571315765]\n"
     ]
    }
   ],
   "source": [
    "print(len(grid))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.8442 - accuracy: 0.4506\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.8258 - accuracy: 0.4611\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7586 - accuracy: 0.5240\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7469 - accuracy: 0.5419\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.5689\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.6198\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6527\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.6272\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6602\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6632\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.6796\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.6856\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5585 - accuracy: 0.7081\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.7006\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7081\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5755 - accuracy: 0.7186\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.6991\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.6886\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.6901\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7111\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7036\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.7036\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5586 - accuracy: 0.7260\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.6991\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7231\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7096\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7350\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7515\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7246\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7201\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7260\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.7470\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.7081\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7395\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7111\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7455\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7410\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7275\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.7335\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7590\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7365\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7425\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7560\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7365\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7141\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7305\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7335\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7350\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7485\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5350 - accuracy: 0.7275\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7545\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7440\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7590\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7290\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7754\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7485\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7590\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7395\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7380\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7530\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7305\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7575\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7605\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7560\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7695\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7425\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5047 - accuracy: 0.7560\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7515\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5158 - accuracy: 0.7650\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7560\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.7395\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.7560\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.7530\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7425\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.7605\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7410\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7575\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7485\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7590\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7605\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7829\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7695\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.7665\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7590\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7425\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7650\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.7410\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.7515\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7545\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7710\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7470\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7395\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7560\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15b262e4310>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = build_model(int(result[0][0]), int(result[0][1]), result[0][2], result[0][3])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 20)\n",
    "tuned_model.fit(X_train, y_train, epochs = 100, callbacks = callback, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.490849107503891, 0.7799999713897705]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
